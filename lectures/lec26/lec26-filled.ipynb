{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02aef81",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to get everything set up.\n",
    "from lec_utils import *\n",
    "import lec26_util as util\n",
    "from ipywidgets import interact\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b01e4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 26\n",
    "\n",
    "# Clustering\n",
    "\n",
    "### EECS 398-003: Practical Data Science, Fall 2024\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> ‚Ä¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/fa24\">github.com/practicaldsc/fa24</a></small>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff724691",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements üì£\n",
    "\n",
    "- Homework 11 is cancelled ‚Äì everyone will receive 100% on it!\n",
    "- If you're still working on Homework 10, make sure to read [**#346 on Ed**](https://edstem.org/us/courses/61012/discussion/5814556) for updates:\n",
    "    - The autograder denominator has been lowered from 24 to 22.\n",
    "    - The deadline for the optional prediction competition in Question 3.4 has been moved to Monday 12/9.\n",
    "- The Portfolio Homework is due on Saturday, and **slip days are not allowed!**<br><small>Take a look at the feedback on your checkpoint submission on Gradescope! We'll open the submission portals on Gradescope by tomorrow.</small>\n",
    "- The Final Exam is on **Thursday, December 12th**.\n",
    "    - 25-35% of the questions will be about pre-midterm content; the rest will be about post-midterm content.\n",
    "    - You can bring 2 double-sided handwritten notes sheets.\n",
    "    - We have two review sessions next week, one on Monday from 6:30-8:30PM and one on Tuesday from 5-7PM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228ba2b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Please give us feedback! üôè"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa818a25",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- We're looking for your feedback to help improve the course for future offerings and decide where it sits in the overall EECS/DS curriculum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb53450",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- If **at least 85% of the class** fills out **both**:\n",
    "    - This [**internal End-of-Semester Survey**](https://docs.google.com/forms/d/e/1FAIpQLSfM0KHvq71kkyYHAKXHAD4Dk_mJx1P38o7PKhaN4U_xequ00Q/viewform), **and**\n",
    "    - the [**Official Campus Evaluations**](https://umich.bluera.com/umich/),<br>\n",
    "    \n",
    "    then we will add 1% of extra credit to everyone's overall grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ff289",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- The deadline to fill out both is on **Tuesday, December 10th at 11:59PM**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b69cf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c4aa9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Today's focus is on **clustering**, an **unsupervised learning** method. We'll focus on $k$-means clustering, the most popular clustering technique, but discuss another clustering technique (agglomerative clustering) as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513d373",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- In our final lecture on Thursday, we'll give many examples of other techniques in machine learning that are small extensions to what we've covered so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76750957",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168106b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587dcc6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The taxonomy of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc077838",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/taxonomy.svg\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10be65",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In Lectures 14-22, we focused on building models for **regression**.<br><small>In regression, we predict a **continuous** target variable, $y$, using some features, $X$.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64d2db7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the past few lectures, we switched our focus to building models for **classification**.<br><small>In classification, we predict a **categorical** target variable, $y$, using some features, $X$.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b459a5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Both regression and classification are **supervised learning** methods.<br><small>In both regression and classification, our goal is to predict $y$ from $X$. The datasets we've used already had a $y$ variable.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d70e1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What might an **unsupervised learning** problem look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d013d57b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: TV show ratings üì∫"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ebc51",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose we have the ratings that several customers of a streaming service gave to two popular TV shows: _Modern Family_ and _Stranger Things_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10961b9a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e039ad",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The data naturally falls into three groups, or **clusters**, based on users with similar preferences.<br><small>All we're given are the ratings each customer gave to the two shows; the customers aren't already part of any group.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23af19f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we ran the streaming service and could \"identify\" the three clusters, it could help inform us on who to make recommendations to.<br><small>For example, if someone in the bottom-right cluster likes _How I Met Your Mother_, we might recommend it to other members of the bottom-right cluster since they have similar tastes.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a35c108",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **How do we algorithmically determine these clusters**, especially when there are too many dimensions to visualize?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e951f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941f1c4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Goal**: Given a set of $n$ data points stored as vectors in $\\mathbb{R}^d$, $\\vec x_1, \\vec x_2, ..., \\vec x_n$, and a positive integer $k$, **place the data points into $k$ clusters of nearby points**.<br><small>In the scatter plot below, $n = 9$ and $d = 2$.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8856dc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f737b9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Think of clusters as **colors**; in other words, the goal of clustering is to assign each point a color, such that points of the same color are similar to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c46b6e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note, unlike with regression or classification, there is no \"right answer\" that we're trying to predict ‚Äì there is no $y$! This is what makes clustering **unsupervised**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5455ec5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34e9fdd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Idea: Points in a cluster should be close to the center of the cluster.**<br><small>The clustering method we're developing relies on this assumption.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3f7186",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **One** technique for defining clusters involves choosing $k$ cluster centers, known as **centroids**.\n",
    "\n",
    "    $$\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k \\in \\mathbb{R}^d$$\n",
    "\n",
    "    For instance, $\\vec \\mu_2$ is the center of cluster 2.<br><small>Cluster 2 might be the set of points colored **<span style=\"color:blue\">blue</span>**, for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f865cbf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- These $k$ centroids define the $k$ clusters; each data point \"belongs\" to the nearest centroid to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4499f54e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Our problem reduces to **finding the best locations for the centroids**.<br><small>Over the next few slides, we'll visualize several possible sets of centroids and the clusters they define.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa331ef",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- With the following $k = 3$ centroids, the data are colored in the way that we'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd34eb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 7), (8, 4), (8, 8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6bbdec",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- But here, even though $k = 3$, the data are not colored \"naturally\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc1f48",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 7), (8, 4), (3, 7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff745206",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Nothing is stopping us from setting $k = 2$, for instance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9486682",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 7), (8, 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a0c317",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Or $k = 5$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4ae1b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(4, 4), (5, 5), (6, 6), (7, 7), (8, 8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146e4d9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflections on choosing a centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a318961b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some values of $k$ seemed more intuitive than others; $k$ is a **hyperparameter** that we'll need to tune.<br><small>More on this later.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38119d0d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For a fixed $k$, some clusterings \"looked\" better than others; we'll need a way to quantify this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b67f3e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we did at the start of the second half of the course, we'll formulate an **objective function** to minimize. Specifically, we'll minimize **inertia**, $I$:\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a4fa2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Lower values of inertia lead to better clusterings; our goal is to find the set of centroids $\\vec \\mu_1, \\vec \\mu_2, ... \\vec \\mu_k$ that **minimize inertia**, $I$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e4b963",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "### Activity\n",
    "    \n",
    "Recall, inertia is defined as follows:\n",
    "    \n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n",
    "    \n",
    "<br>\n",
    "    \n",
    "Suppose we arrange the dataset below into $k = 2$ clusters. What is the **minimum possible inertia**?\n",
    "    \n",
    "<center><img src=\"imgs/example-q.png\" width=500></center>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032cd09",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## $k$-means clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d5e79a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimizing inertia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77feba61",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Goal**: Find the centroids $\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k$ that minimize inertia:\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386b23f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Issue**: There is no efficient way to find the centroids that minimize inertia!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba577e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are $k^n$ possible assignments of points to clusters; it would be computationally infeasible to try them all.<br><small>It can be shown that finding the optimal centroid locations is NP-hard.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48ada0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can't use calculus to minimize $I$, either ‚Äì we use calculus to minimize continuous functions, but the assignment of a point $\\vec x_i$ to a centroid $\\vec \\mu_j$ is a discrete operation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d273aa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-means clustering (i.e. Lloyd's algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a4e06",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Fortunately, there's an efficient algorithm that (tries to) find the centroid locations that minimize inertia. The resulting clustering technique is called **$k$-means clustering**.<br><small>Note that this has no relation to $k$-nearest neighbors, which we used for both regression and classification. Remember that clustering is an unsupervised technique!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03334b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. **Randomly** initialize $k$ centroids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8abf91a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Assign each point to the nearest centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c721e5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Move each centroid to the center of its group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d24478",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. **Repeat** steps 2 and 3 until the centroids stop changing!<br><small>This is an iterative algorithm!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0ee73",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize a few iterations ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3eed6a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 5), (8, 10)], show_color=False, title='Step 1: Random Initialization<br>Red:(2, 5), Blue: (8, 10)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1066eff4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 5), (8, 10)], title='Iteration 1, Step 2: Assign each point to the nearest centroid<br>Red:(2, 5), Blue: (8, 10)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75166a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2, 5), (8, 10)], lines=True, title='Iteration 1, Step 2: Assign each point to the nearest centroid<br>Red:(2, 5), Blue: (8, 10); <b>Inertia = Sum(squared distances) = 156.25</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4abb64",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(3.6, 6.8), (9.5, 7.125)], lines=True, assignments=[0] * 5 + [1] * 4, title='Iteration 1, Step 3: Move each centroid to the center of its group<br>Red:(3.6, 6.8), Blue: (9.5, 7.125); <b>Inertia = 85.1875</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd0694",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(3.6, 6.8), (9.5, 7.125)], assignments=[0] * 5 + [1] * 4, title='Iteration 1, Step 3: Move each centroid to the center of its group<br>Red:(3.6, 6.8), Blue: (9.5, 7.125); <b>Inertia = 85.1875</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5946da2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(3.6, 6.8), (9.5, 7.125)], title='Iteration 2, Step 2: Assign each point to the nearest centroid<br>Red:(3.6, 6.8), Blue: (9.5, 7.125); <b>Inertia = 70.653125</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1396a79e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2.5, 7.75), (9.2, 6.3)], title='Iteration 2, Step 3: Move each centroid to the center of its group<br>Red:(2.5, 7.75), Blue: (9.2, 6.3); <b>Inertia = 58.35</b>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269bcdc1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.visualize_centroids([(2.5, 7.75), (9.2, 6.3)], title='Iteration 3, Step 2: Assign each point to the nearest centroid<br>No change, so algorithm terminates!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e770cc2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why does $k$-means work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8720fc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- On each iteration, **inertia can only stay the same or decrease** ‚Äì it cannot increase.\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eca008",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why? Step 2 and step 3 **alternate** minimizing inertia in different ways:\n",
    "    - In Step 2, we assign each point to the nearest centroid; this reduces the squared distance of each point to its closest centroid.\n",
    "    - In Step 3, we move the centroids to the \"middle\" of their groups; this reduces the total squared distance from a centroid to the points assigned to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ba336",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since there are only finitely many possible assignments of points to clusters, eventually the algorithm will terminate at some **potentially local** minimum.<br><small>Read more on the theory [**here**](https://www.cs.toronto.edu/~rgrosse/courses/csc311_f21/lectures/lec11.pdf).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a073b435",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e22ae6c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize more runs of the algorithm [**here**](https://www.naftaliharris.com/blog/visualizing-k-means-clustering).\n",
    "\n",
    "<center><img src=\"imgs/smiley.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc6733",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To replicate the picture above, select \"I'll Choose\" and \"Smiley Face.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73746479",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In what sense is $k$-means _optimal_?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb4911c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The algorithm discussed **isn't guaranteed** to find the centroids that minimize inertia; depending on the initially-chosen centroids, it may converge at a local minimum.<br><small>One solution is $k$-means++, which picks one centroid randomly and chooses the others in a way that maximizes distance from existing centroids. Read more [here](https://en.wikipedia.org/wiki/K-means%2B%2B).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce3f9f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Even if $k$-means \"works\", the resulting clustering might not look \"right\" to humans. That is, the clustering that minimizes inertia doesn't necessarily look correct to us.<br><small>Remember, the core assumption in $k$-means is that **points in a cluster should be close to the center of the cluster**. This assumption isn't always true!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100337d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choosing the number of clusters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016be395",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Choosing $k$ in $k$-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc567f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Given a dataset, how do we choose $k$, the number of clusters to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97eefaf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The larger the value of $k$, the smaller inertia is.\n",
    "\n",
    "$$I(\\vec \\mu_1, \\vec \\mu_2, ..., \\vec \\mu_k) = \\text{total squared distance} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{of each point } \\vec x_i \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{ to its closest centroid } \\vec \\mu_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ebf2ed",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $k = n$, then each point is a centroid, and inertia is 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dcf70",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But, the goal of clustering is to put the data into groups, so a large number of groups may not be meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1aaff4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9852156c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f06b0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For several different values of $k$, let's compute the inertia of the resulting clustering, using the scatter plot from the previous slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c5b0ee",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "util.show_elbow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bebfdad",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **elbow method** says to choose the $k$ that appears at the elbow of the plot of inertia vs. $k$, since there are diminishing returns for using more than $k$ clusters.<br><small>Above, we see an elbow at $k = 3$, which gives us the $k$ that matches our natural intuition in this example.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d0b9d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In practice, the data may not have natural clusters, so the choice of $k$ may not be so obvious.<br><small>And, there may be other business reasons to choose a specific value of $k$, e.g. if you're told to categorize customers of a clothing item into 5 groups: XS, small, medium, large, XL.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58de1b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd09691",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: World Bank data üåé\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2c3b4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074947c1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Below, we load in a dataset containing hundreds of attributes per country, taken from the [World Bank](https://databank.worldbank.org/source/world-development-indicators#)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf7191a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_bank = pd.read_csv('data/world_bank_data.csv').set_index('country').fillna(0)\n",
    "world_bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7dbfc3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are $d = 209$ features, far too many to visualize before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb8763",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_bank.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a31eaa4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Dimensionality reduction** is another form of unsupervised learning that would help us visualize the data; we'll explore it briefly next class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27e998",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The elbow method, revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281f5fa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How many clusters should we use? We'll need to resort to the elbow method, since we can't visualize the data to see how many \"natural\" clusters there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef1d35",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_elbow_world_bank(world_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f616d1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The choice is a bit more ambiguous than before; here, we'll use $k = 6$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d974b4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clustering in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3462a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To create our clusters, we'll use `KMeans` in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d9978",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3199d5f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like other models we've used in `sklearn`, we need to instantiate and fit a `KMeans` object. The difference is that the `fit` method only takes in a single `X`, not an `X` and `y`.<br><small>$k$-means is an unsupervised method, so there is no `y`.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1098dd3f",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The default value of k is 8; we should generally specify another value.\n",
    "# We fix a random_state for reproducibility; remember the centroids are generally initialized randomly.    \n",
    "model = KMeans(n_clusters=6, random_state=15)\n",
    "model.fit(world_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d78a99",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A fit `KMeans` instance has a `predict` method. It outputs the cluster whose centroid the data point is closest to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdd2bb",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.predict(world_bank.loc[['United States']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a146cd3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# It seems that the US and Canada are assigned to different clusters!\n",
    "model.predict(world_bank.loc[['Canada']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f665463",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspecting clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983838c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can view the countries assigned to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80774b64",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "countries_and_clusters = pd.Series(model.labels_, index=world_bank.index)\n",
    "util.list_countries_by_cluster(countries_and_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5110b25d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It seems that the vast majority of countries are assigned to the same cluster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47ce18",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbfaa7",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.country_choropleth(countries_and_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f78160",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Standardize before clustering!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f0d1c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Clustering, like $k$-nearest neighbors and regularization, is a **distance-based method**, meaning that it **depends on the scale of the data**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f8062",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In `world_bank`, some features are in the millions or billions, while some are in the single digits. The larger features will influence cluster membership more than the smaller features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea2045",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "world_bank.iloc[[1], -9:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea051d06",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: Standardize before clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc957c4d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f69a8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_std = make_pipeline(StandardScaler(), KMeans(n_clusters=6, random_state=15)) # We fix a random state for reproducibility.\n",
    "model_std.fit(world_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1988725c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Once we standarize, the sizes of the clusters seem to be a bit more evenly distributed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a421a67",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "countries_and_clusters_std = pd.Series(model_std[-1].labels_, index=world_bank.index)\n",
    "util.list_countries_by_cluster(countries_and_clusters_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e242790",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing clusters after standardizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade35258",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that the colors themselves are arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8f12a",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.country_choropleth(countries_and_clusters_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e5f05",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agglomerative clustering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf50946",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overview of clustering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399fc00b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn` supports many different clustering methods! Read about them all [**here**](https://scikit-learn.org/1.5/modules/clustering.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02257fa0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/clustering-methods.png\" width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be5bdaf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Remember the \"no free lunch theorem\" ‚Äì there isn't a clustering method that is **always** better than all other clustering methods. It depends on the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c213d2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agglomerative clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f8b7f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's revisit the ratings dataset from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed296643",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f04af0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Agglomerative clustering**, a form of **hierarchical clustering**, creates clusters by:\n",
    "    1. Starting with each point as its own cluster.\n",
    "    2. Repeatedly **combining the two closest clusters** until there are only $k$ clusters remaining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e43507",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's visualize it in the context of this dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80aacc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84a20f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The two closest clusters are <b><span style=\"color:brown\">cluster 7</span></b> and <b><span style=\"color:navy\">cluster 8</span></b>, so we merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993cf32b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 1', labels=[0, 1, 2, 3, 4, 5, 6, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee8eed",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Now, the two closest clusters are <b><span style=\"color:cyan\">cluster 5</span></b> and <b><span style=\"color:magenta\">cluster 6</span></b>, so we merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d0541",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 2', labels=[0, 1, 2, 3, 4, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4b76c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's not clear what the next merge should be ‚Äì should <b><span style=\"color:orange\">cluster 4</span></b> merge with <b><span style=\"color:cyan\">cluster 5</span></b> or should <b><span style=\"color:green\">cluster 2</span></b> merge with <b><span style=\"color:purple\">cluster 3</span></b>?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8bb03",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linkage criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b452c4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We need a way to measure the distance between two clusters.<br><small>For example, what is the \"distance\" between <b><span style=\"color:orange\">cluster 4</span></b> and <b><span style=\"color:cyan\">cluster 5</span></b> below?</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f801b827",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 2', labels=[0, 1, 2, 3, 4, 5, 5, 7, 7], width=500, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b13a23",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **linkage criteria** determines how to compute the distance between  two clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4b0ec",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some examples:\n",
    "    - Average linkage: The average distance between points in both clusters.\n",
    "    - Single linkage: The minimum distance between points in both clusters.\n",
    "    - Complete linkage: The maximum distance between points in both clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a9d91",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 2', show_distances=[(1, 3), (0, 2), (0, 1), (2, 3), (4, 5)], labels=[0, 1, 2, 3, 4, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2bdfa8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We'll use single linkage, i.e.:\n",
    "\n",
    "$$\\text{distance(cluster $A$, cluster $B$)} = \\text{minimum distance between} \\\\ \\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\:\\: \\text{any point in $A$ and any point in $B$}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d759b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Here, there are lots of ties; we'll arbitrarily choose to merge <b><span style=\"color:orange\">cluster 4</span></b> and <b><span style=\"color:cyan\">cluster 5</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3568126",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 3', show_distances=[(0, 2), (2, 3)], labels=[0, 1, 2, 3, 5, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b628e1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Again, there's a tie; we'll arbitrarily choose to merge <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:purple\">cluster 3</span></b>.<br><small>We could have also merged <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:red\">cluster 0</span></b>, since their minimum distance is also the same.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b159922",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 4', show_distances=[(0, 2), (1, 2)], labels=[0, 1, 2, 2, 5, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c568b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Next, we merge <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:red\">cluster 0</span></b>.<br><small>Why? Because the minimum distance between <b><span style=\"color:red\">cluster 0</span></b> and <b><span style=\"color:green\">cluster 2</span></b> is less than the minimum distance between <b><span style=\"color:blue\">cluster 1</span></b> and <b><span style=\"color:green\">cluster 2</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c8145",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.color_ratings(title='Iteration 5', labels=[2, 1, 2, 2, 5, 5, 5, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50977baf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- And finally, we merge <b><span style=\"color:green\">cluster 2</span></b> and <b><span style=\"color:blue\">cluster 1</span></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e666b3f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we just want $k = 3$ clusters, we stop here! If we wanted $k = 2$ clusters, we'd then merge the two closest clusters, based on the single linkage criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2841562e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-means vs. agglomerative clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460fc09d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- On what sorts of datasets does agglomerative clustering perform better than $k$-means clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d00919",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_scatter_comp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a7a86",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.show_scatter_comp_k_means(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a53d0df",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that $k$-means clustering optimizes for inertia, not \"blobiness.\" It doesn't work well when the natural clusters are of uneven sizes.<br><small>Read more [**here**](https://stats.stackexchange.com/questions/133656/how-to-understand-the-drawbacks-of-k-means)!</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7147cd3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.show_scatter_comp_agg(k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079984c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Another metric that's used to compare different clusterings is the **silhouette score**.<br><small>Read more [**here**](https://en.wikipedia.org/wiki/Silhouette_(clustering))!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3aece",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
