{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad096bf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to get everything set up.\n",
    "from lec_utils import *\n",
    "import lec27_util as util\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c93f3f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" markdown=\"1\">\n",
    "\n",
    "#### Lecture 27\n",
    "\n",
    "# Computer Vision, Conclusion\n",
    "\n",
    "### EECS 398-003: Practical Data Science, Fall 2024\n",
    "\n",
    "<small><a style=\"text-decoration: none\" href=\"https://practicaldsc.org\">practicaldsc.org</a> ‚Ä¢ <a style=\"text-decoration: none\" href=\"https://github.com/practicaldsc/fa24\">github.com/practicaldsc/fa24</a></small>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b711aa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements üì£\n",
    "\n",
    "- Homework 11 is cancelled ‚Äì everyone will receive 100% on it!\n",
    "- The Portfolio Homework is due on Saturday, and **slip days are not allowed!**<br><small>Remember to submit both your notebook PDF and the link to your website.<br>There's a remote office hour on Saturday!</small>\n",
    "- The optional, **extra credit** prediction competition in Homework 10 is open until Monday.\n",
    "- If **at least 85% of the class** fills out **both**:\n",
    "    - This [**internal End-of-Semester Survey**](https://docs.google.com/forms/d/e/1FAIpQLSfM0KHvq71kkyYHAKXHAD4Dk_mJx1P38o7PKhaN4U_xequ00Q/viewform), **and**\n",
    "    - the [**Official Campus Evaluations**](https://umich.bluera.com/umich/),<br>\n",
    "\n",
    "    then we will add 1% of extra credit to everyone's overall grade.<br><br>Deadline: **Tuesday, December 10th at 11:59PM**.\n",
    "- Discussion tomorrow is replaced with office hours (in the regular discussion section rooms and times)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c138d21e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Final exam details üôá"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79217574",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The Final Exam is on **Thursday, December 12th from 4-6PM**.<br><small>You'll receive your assigned room via email by Monday.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12db770",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 25-35% of the questions will be about pre-midterm content; the rest will be about post-midterm content.<br><small>All questions on the exam will count towards your final exam score. See the [**Redemption Policy**](https://practicaldsc.org/syllabus/#redemption-policy) in the syllabus.</small>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c62c262",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- You can bring 2 double-sided handwritten notes sheets.<br><small>Feel free to bring your midterm notes sheet as one of your two sheets!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f4065",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We have two review sessions next week, one on Monday from 6:30-8:30PM (pre-midterm content) and one on Tuesday from 5-7PM (post-midterm content), both in 1670 BBB.<br><small>Both will be recorded. Format TBD, but if we know in advance which problems we plan to cover, we'll let you know over the weekend so you can come prepared.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c2214",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- See [**this post on Ed**](https://edstem.org/us/courses/61012/discussion/5768889) for some studying tips.<br><small>The [**study site**](https://study.practicaldsc.org) is the most important resource, followed by lecture slides, and then assignments.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eceaed",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508768c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Reflection ü§î.\n",
    "- Computer vision üëæ.\n",
    "- Parting thoughts üí≠."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de841b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5143724",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reflection üí≠\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac4c01",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From Lecture 1: Topics\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"width: 100%; height: 100%\">\n",
    "<div style=\"width: 50%; float: left\"> \n",
    "\n",
    "- Week 1: Python and Jupyter Notebooks.\n",
    "- Weeks 2-3: `numpy`, `pandas`, and Exploratory Data Analysis.\n",
    "- Weeks 4-5: Missing Data; Web Scraping and APIs.\n",
    "- Weeks 5-6: Text Processing.\n",
    "- Week 7: **Midterm Exam**.\n",
    "- Weeks 8-10: Linear Regression through Linear Algebra.\n",
    "- Weeks 11-12: Generalization, Regularization, and Cross-Validation.\n",
    "- Weeks 12-14: Gradient Descent and Logistic Regression.\n",
    "- Weeks 15-16: Unsupervised Learning, **Final Exam**.\n",
    "    \n",
    "</div>\n",
    "<div style=\"margin-left: 60%; height: 1px\" markdown=\"1\"> \n",
    "\n",
    "<center><img src=\"imgs/lifecycle-trimmed.png\">\n",
    "    \n",
    "The **data science lifecycle**, which we've revisited repeatedly throughout the semester.\n",
    "</center>\n",
    "\n",
    " \n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cadf44",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### You've accomplished a lot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4a74a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- You learned **a lot** this semester ‚Äì you're now among **the most qualified data scientists in the world**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799f692",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- You're now **able to start with raw data and come up with accurate, meaningful insights that you can share with others**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a168cde",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- You know how to use industry-standard data manipulation tools, and you understand the inner-workings of complicated statistical models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb0398d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- You're well-prepared for internships and data science interviews, ready to create your own portfolio of personal projects, and have the background and maturity to succeed in more advanced data science-adjacent courses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332d14d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41734d8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Data science is a relatively new, rapidly evolving field, **so you'll need to keep evolving with it**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87681509",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Fun fact**: One of the earliest uses of the term _data science_ in a lecture given **here at U‚ÄìM** in 1997 by former statistics and IOE Professor C.F. Jeff Wu:\n",
    "\n",
    "    > In his 1997 inaugural lecture for the Carver Chair , he coined the term data science and advocated that statistics be renamed data science and statistician to data scientist.  ([source](https://www.isye.gatech.edu/users/jeff-wu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e931496a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The tools of the trade may change, but the core principles won't ‚Äì you now have a strong foundation on which you can develop new skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10000005",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computer vision üëæ\n",
    "\n",
    "---\n",
    "\n",
    "We'll wrap up the semester by looking at a fun application area of the tools we've seen ‚Äì computer vision. None of the <b>new</b> material today is in scope for the exam, but a lot of it is implicitly review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d4e32",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    \n",
    "<img src=\"imgs/digits-intro.png\" width=1000>\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395b5fb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><b>Goal</b>: Given an image of a digit, <b>classify</b> the digit as either 0, 1, 2, 3, 4, 5, 6, 7, 8, or, 9.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225efac",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>This is a multi-class <b>classification</b> problem with 10 classes.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ba6f1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>This is also an example of <b>computer vision</b>, <br>a branch of machine learning that deals with learning patterns in images and videos.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fa3e19",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db5744",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The MNIST dataset contains 70,000 **labeled** images of digits, all of which are **28 pixels by 28 pixels** and grayscale (no color).<br><small>MNIST stands for \"Modified National Institute of Standards and Technology\". Yann LeCun et. al. are responsible for curating the dataset, read the original webpage for it [**here**](https://yann.lecun.com/exdb/mnist/). </small>\n",
    "\n",
    "<center><img src=\"imgs/mnist-many.jpg\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ef7a7a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The dataset is pre-split into a training set of 60,000 images and test set of 10,000 images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab8dd96",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Test set performance on MNIST is a common benchmark for evaluating the quality of a classifier.<br><small>Convolutional neural networks, one of the most popular model architectures for computer vision, were developed specifically in the context of achieving high accuracy on MNIST.<br>There are other, similarly-purposed datasets too, like FashionMNIST.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f6865",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- State of the art **neural network**-based models have achieved test set accuracies of as high as 99.87\\%.<br><small>See the leaderboard [**here**](https://paperswithcode.com/sota/image-classification-on-mnist)!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828accb1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025855e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn` has a built-in function for loading datasets from [OpenML](https://www.openml.org/search?type=data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4fd075",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=True)\n",
    "# The documentation here: https://www.openml.org/search?type=data&status=active&id=554\n",
    "# tells us that the first 60,000 rows constitute the training set.\n",
    "X_train, X_test = X.iloc[:60000], X.iloc[60000:]\n",
    "y_train, y_test = y.iloc[:60000].astype(int), y.iloc[60000:].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3900cb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What do `X_train` and `y_train` actually look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0bf943",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff644e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e64f00",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From vectors to images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75994abf",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In `X_train`, each image is represented by a $28 \\cdot 28 = 784$-dimensional vector, representing a **flattened** version of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c7e41",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train.iloc[98]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ffe937",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The first 28 pixels are the first **row** of the image, the second 28 pixels are the second row of the image, and so on. To view the image, we can **reshape** the vector into a 2D grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed184aec",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train.iloc[98].to_numpy().reshape((28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0574e49",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each pixel is represented with a value from 0 to 255, where **larger values are more intense** (darker in the plot below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c5185",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We'll keep using image 98 as an example, so remember that it's a 3!\n",
    "util.show_image(X_train.iloc[98])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62982fc5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The distribution of the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46912e4",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Before training any models, we should assess whether there's any class imbalance in the **training set**.<br><small>Remember, we shouldn't peek at the test set until we've actually trained a model!</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36632e0",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True).sort_index().plot(kind='bar', title='Distribution of Digits in the Training Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74fce1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The 10 possible digits seem to appear at roughly the same frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dadd0a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #1: $k$-Nearest Neighbors üè°üè†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d16c33",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We _can_ use $k$-nearest neighbors to predict the digit in a new image, $\\vec{x}_\\text{new} \\in \\mathbb{R}^{784}$.<br>Intuitively, this means finding the $k$ \"most similar\" images to $\\vec{x}_\\text{new}$.<br><small>Remember, $k$-nearest neighbors is a **classification** method for **supervised learning**!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d12e2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since we're treating each image in our training set as a \"flat\" vector in $\\mathbb{R}^{784}$, we're ignoring any **spatial** patterns in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f3e0cc",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d105c8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=100) # Arbitrary choice; remember, there are 60,000 points in the training set.\n",
    "model_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda7f3a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that \"training\" a $k$-NN classifier (i.e. calling `fit`) is instant, because nearest neighbor models do all of their calculation upon calling `predict`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5deed3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Calling `predict` is much slower than calling `fit` ‚Äì for each input to `predict`, the model must find the distance between the input vector and all 60,000 vectors in the training set to see which $k=100$ are the closest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89957792",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_knn.predict(X_train.iloc[[98]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c97cb8",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Accuracy on test set. Takes ~10 seconds on my computer, but is fairly high!\n",
    "y_test_pred = model_knn.predict(X_test)\n",
    "(y_test == y_test_pred).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71304e41",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What kinds of errors does the model make?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da70531d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A 100-nearest neighbor classifier achieves 94.4\\% test set accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1196ce",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To further understand the classifier's performance, we can draw its **confusion matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc047851",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_test_labeled = X_test.assign(\n",
    "    true=y_test,\n",
    "    pred=y_test_pred\n",
    ")\n",
    "util.show_confusion(y_test, y_test_pred, title='Confusion Matrix for 100-Nearest Neighbors Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98424e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some of the most common errors seem to be:\n",
    "    - Predicting 1 when the true digit is 2 or 7.\n",
    "    - Predicting 7 when the true digit is 2.\n",
    "    - Predicting 9 when the true digit is 4 or 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610fccc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's peek at some of those cases!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf9fd2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Examining misclassified images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5728e6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Run the cell below repeatedly to see a randomly-chosen image from the test set that we classified incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d209d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_image_and_label(X_test_labeled.query('pred != true').sample().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef25469",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Run the cell below repeatedly to see a randomly-chosen image from the test set that **we incorrectly classified as a 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b62305",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_image_and_label(X_test_labeled.query('pred != true and pred == 1').sample().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e7461",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf155e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Downsides of $k$-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df1d325",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the example below, our 100-nearest neighbor classifier predicted 1, when the true label was 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d83614",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_image_and_label(X_test_labeled.query('pred != true and pred == 1').iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b135bfb1",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One downside: $k$-nearest neighbors doesn't incorporate any **probability** in its decision-making process. What if we could get a probability that the above image is of a 0, 1, 2, 3, ..., 9?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52287046",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Another downside: Classifying a new image takes relatively long. What if we could learn patterns from the training set in advance, so that predicting new images is relatively quick?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8648d47e",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What about logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938cbdd6",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As we've seen, in **binary classification**, logistic regression models **the probability of belonging to class 1, given a feature vector $\\vec{x}_i \\in \\mathbb{R}^{784}$**:\n",
    "\n",
    "$$P(y_i = 1 | \\vec{x}_i) = \\sigma (w_0 + w_1 x_i^{(1)} + w_2 x_i^{(2)} + ... + w_d x_i^{(d)}) = \\sigma\\left(\\vec{w} \\cdot \\text{Aug}(\\vec{x}_i) \\right)$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8dffb2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In logistic regression, $y_i \\in \\{0, 1\\}$. But, in our current image classification problem, $y_i \\in \\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\\}$, so we can't use logistic regression directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d92a79",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One idea: **one-vs-rest**. Fit 10 separate logistic regression models ‚Äì one per class ‚Äì and predict the class that has the highest probability.\n",
    "    - Image is 0 vs. image is not 0.\n",
    "    - Image is 1 vs. image is not 1.\n",
    "    - ...\n",
    "    - Image is 9 vs. image is not 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26458a36",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Another idea: **one-vs-one**. Fit ${10 \\choose 2} = 55$ separate logistic regression models ‚Äì one per pair of classes ‚Äì and predict the class that \"wins\" the most predictions.\n",
    "    - Image is 0 vs. image is 1.\n",
    "    - Image is 0 vs. image is 2.\n",
    "    - ...\n",
    "    - Image is 8 vs. image is 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026cfb06",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's try something slightly different than listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2649000b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #2: Multinomial logistic regression üìà"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78645115",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Multinomial** logistic regression, also known as **softmax regression**, models the probability of belonging to **any class, given a feature vector $\\vec x_i \\in \\mathbb{R}^{784}$**.<br><small>Think of it as a generalization of logistic regression.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271cdac8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Multinomial logistic regression models the probability of each class directly, and then predicts the most likely class.<br>Let $p_j$ represent the modelled probability of class $j$, given a feature vector. Note that $j \\in \\{0, 1, ..., 9\\}$.<br>Then, for instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac168f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$p_0 = P(y_i = 0 | \\vec{x}_i) = \\frac{e^{\\vec{w}_0 \\cdot \\text{Aug}(\\vec{x}_i)}}{\\sum_{j = 0}^9 e^{\\vec{w}_j \\cdot \\text{Aug}(\\vec{x})}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d56248",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$p_3 = P(y_i = 3 | \\vec{x}_i) = \\frac{e^{\\vec{w}_3 \\cdot \\text{Aug}(\\vec{x}_i)}}{\\sum_{j = 0}^9 e^{\\vec{w}_j \\cdot \\text{Aug}(\\vec{x})}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99937931",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$p_k = P(y_i = k | \\vec{x}_i) = \\frac{e^{\\vec{w}_k \\cdot \\text{Aug}(\\vec{x}_i)}}{\\sum_{j = 0}^9 e^{\\vec w_j \\cdot \\text{Aug}(\\vec x_i)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a9055",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Instead of a single parameter vector $\\vec{w}$, there are 10 parameter vectors, $\\vec w_0$, $\\vec w_1$, ..., $\\vec w_9$!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4d1fa",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: The softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c843bd3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The **softmax** function is a generalization of the logistic function to multiple dimensions.<br>\n",
    "Suppose $\\vec z \\in \\mathbb{R}^d$. Then, the softmax of $\\vec z$ is defined element-wise as follows:\n",
    "\n",
    "$$\\sigma(\\vec z)_i = \\frac{e^{z_i}}{\\sum_{j = 1}^d e^{z_j}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a5523",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For example, suppose $\\vec{z} = \\begin{bmatrix} -5 \\\\ 2 \\\\ 4 \\end{bmatrix}$. Then:\n",
    "\n",
    "$$\\sigma(\\vec z) = \\begin{bmatrix} \\sigma(\\vec z)_1 \\\\ \\sigma(\\vec z)_2 \\\\ \\sigma(\\vec z)_3  \\end{bmatrix} = \\underbrace{\\begin{bmatrix} \\frac{e^{-5}}{e^{-5} + e^2 + e^4} \\\\ \\frac{e^{2}}{e^{-5} + e^2 + e^4} \\\\ \\frac{e^{4}}{e^{-5} + e^2 + e^4} \\end{bmatrix}}_\\text{note the constant denominator!} = \\begin{bmatrix} 0.0001 \\\\ 0.1192 \\\\ 0.8807 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dade83",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why is it defined this way? **It maps a vector of real numbers to a vector of probabilities!**<br><small>Note that the denominator, $\\sum_{j=1}^d e^{z_j}$, normalizes the $e^{z_i}$ terms so that the results sum to 1.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec010cb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Multinomial logistic regression, i.e. softmax regression, trains 10 linear models of the form $\\vec w_j \\cdot \\text{Aug}(\\vec x_i)$ ‚Äì one per class, $j$ ‚Äì and feeds the output of each through the softmax function, so the results can be interpreted as probabilities.\n",
    "\n",
    "    $$P(y_i = k | \\vec{x}_i) = \\frac{e^{\\vec w_k \\cdot \\text{Aug}(\\vec x_i)}}{\\sum_{j = 0}^9 e^{\\vec w_j \\cdot \\text{Aug}(\\vec x_i)}}$$\n",
    "\n",
    "    The 10 optimal parameter vectors, $\\vec w_0^*$, $\\vec w_1^*$, ..., $\\vec w_9^*$, are chosen to minimize mean cross-entropy loss, just like before!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee02068",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multinomial logistic regression in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f763b2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The `LogisticRegression` class supports multinomial logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2e829c",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_log = LogisticRegression(multi_class='multinomial', penalty='l1', solver='saga')\n",
    "model_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c302438",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Given that we have 60,000 training examples, each of which are 784-dimensional, training on the full training set takes quite a while ‚Äì longer than we have time to run in lecture! Just to demonstrate, we'll fit on just the first 10,000 rows of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b29d4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_log.fit(X_train.head(10000), y_train.head(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8125de0",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- While calling `fit` takes a while, calling `predict` is fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebef3c3",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_image(X_train.iloc[[98]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2e0aa",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_log.predict(X_train.iloc[[98]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab994ca5",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# MUCH faster than with the k-nearest neighbors model!\n",
    "model_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab568bc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What kinds of errors does _this_ model make?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b5c475",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The our multinomial logistic regression model, trained on just the first 10,000 rows of the training set, achieves 90.12\\% test set accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf891afd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's peek at the confusion matrix once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91594569",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_test_labeled = X_test.assign(\n",
    "    true=y_test,\n",
    "    pred=model_log.predict(X_test)\n",
    ")\n",
    "util.show_confusion(y_test, model_log.predict(X_test), title='Confusion Matrix for Multinomial Logistic Regression Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645afd0c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The most common types of errors are now different! Common errors:\n",
    "    - Predicting 8 when the true digit is a 2 or 5.\n",
    "    - Predicting 3 when the true digit is a 5 (or vice versa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd117131",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modeling uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f802cd7",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's look at test set images that the multinomial logistic regression model misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ec563",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_image_and_label(X_test_labeled.query('pred != true and pred == 8').iloc[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde3d692",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can use `predict_proba` to see the distribution of predicted probabilities per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5045a972",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_log.predict_proba(X_test_labeled.query('pred != true and pred == 8').iloc[[15], :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2942bd4",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.visualize_probs(model_log.predict_proba(X_test_labeled.query('pred != true and pred == 8').iloc[[15], :-2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b8008f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Other close calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760e37ce",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Repeatedly run the cell below to look at the distribution of predicted probabilities for misclassified examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a56e66",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t = X_test_labeled.query('pred != true').reset_index(drop=True)\n",
    "t = t.assign(second_highest_prob = pd.DataFrame(model_log.predict_proba(t.iloc[:, :-2])).apply(lambda r: r.sort_values().iloc[-2], axis=1))\n",
    "p = t[t['second_highest_prob'] >= 0.3].sample().iloc[0]\n",
    "util.show_image_and_label(p.iloc[:-1].astype(int)).show()\n",
    "util.visualize_probs(model_log.predict_proba(p.iloc[:-3].to_frame().T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba88ea9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b510f",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Since there are 10 classes, `model_log` has 10 parameter vectors (each in $\\mathbb{R}^{784}$) ‚Äì one per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4969e7",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_log.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c1ede",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_log.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c04471",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can visualize these coefficients, too!<br>Below, pixels in <b><span style=\"color:blue\">blue</span></b> had a positive coefficient, i.e. increase the probability of class 0. Pixels in <b><span style=\"color:red\">red</span></b> had a negative coefficient, i.e. decrease the probability of class 0.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65480310",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "px.imshow(model_log.coef_[0].reshape((28, 28)), color_continuous_scale='Rdbu', title='Class 0 Coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a0003",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "util.plot_model_coefficients(model_log.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c50d28",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a style=\"text-decoration: none; color: #0066cc\" href=\"https://docs.google.com/forms/d/e/1FAIpQLSd4oliiZYeNh76jWy-arfEtoAkCrVSsobZxPwxifWggo3EO0Q/viewform\">practicaldsc.org/q</a>)</h3>\n",
    "    \n",
    "Remember that you can always ask questions anonymously at the link above!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2716140",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f8a75c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've fit two models to the MNIST training set so far:\n",
    "    - $k$-nearest neighbors.\n",
    "    - Multinomial logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a94d43b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Both models achieved a test set accuracy above 90\\%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87ea49",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Both models are _slow_ in some sense:\n",
    "    - $k$-nearest neighbors is slow at classifying new images.\n",
    "    - Logistic regression is slow to train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee37992",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- These issues, in part, stem from the fact that our design matrix has $28 \\cdot 28 = 784$ columns, i.e. 784 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211acca",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9eeac",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Is there a way we could **reduce** the number of features we use, i.e. reduce the number of columns in the design matrix, and still achieve decent test set performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d9dd93",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13571ffe",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Principal component analysis (PCA) is an **unsupervised learning** technique used for **dimensionality reduction**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79a806",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It'll allow us to take:\n",
    "    - `X_train`, which has 60,000 rows and 784 columns, and transform it into\n",
    "    - `X_train_approx`, which has 60,000 rows and $p$ columns, where $p$ is as small as we want (e.g. $p = 2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965721fb",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It creates $p$ **new features**, each of which is a linear combination of all existing 784 features.\n",
    "    - That is, it **does not** just select $p$ of the original features! (Here, that would mean just looking at $p$ of the original pixels.)\n",
    "    - These new features are chosen to capture as much variability (information) in the original data as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a058db",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How? The details are out of scope for us, but it leverages the **singular value decomposition** from linear algebra:\n",
    "\n",
    "$$X = U \\Sigma V^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b63ca2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PCA in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e6348",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `sklearn` has an implementation of PCA, which operates like a **transformer**.<br><small>Remember, PCA is an **unsupervised** technique! We don't use the actual digit labels for each image when computing this transformation.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7149d",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e0b11",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb312f6a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Once `fit`, `pca` can transform `X_train` into a **2-column matrix** in a way that retains the bulk of the information:\n",
    "\n",
    "$$\\mathbb{R}^{60000 \\times 784} \\rightarrow \\mathbb{R}^{60000 \\times 2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e034e",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train_approx = pca.transform(X_train)\n",
    "X_train_approx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec3bbd",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train_approx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab56242",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When each data point was 784-dimensional, we couldn't visualize our training set.<br>But now, each data point is 2-dimensional, which we can easily visualize with a scatter plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cae4ab",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999ef6b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The new features that PCA creates are called **principal components (PCs)**.<br><small>Note that the principal component values no longer correspond to pixel intensities, which used to range between 0 and 255.</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab673d95",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Plotting PC 2 vs. PC 1 doesn't lead to a ton of insight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbb253",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_2_pcs(X_train_approx, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f0f6b",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clusters in principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72313a23",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- But what if we color each point by its true class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9346e2",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "util.show_2_pcs(X_train_approx, y_train, color=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb49bc",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea**: Even when projected onto just two principal components, the 0s tend to look alike, the 1s tend to look alike, and so on!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d67f3",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This doesn't always happen when using PCA; use it as part of your exploratory data analysis toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f3ef2",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PCA as a preprocessing step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd88f8",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We can use PCA as part of a larger modeling pipeline. We've chosen a number of principal components to use in advance, but in practice we should cross-validate.\n",
    "\n",
    "$$\\text{raw data in }\\mathbb{R}^{60000 \\times 784} \\rightarrow \\text{transformed data in }\\mathbb{R}^{60000 \\times 30} \\rightarrow \\text{predicted probabilities}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ad728",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "model_pca_log = make_pipeline(\n",
    "    PCA(n_components=30),\n",
    "    LogisticRegression(multi_class='multinomial', penalty='l1', solver='saga')\n",
    ")\n",
    "model_pca_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d15514",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The transformed data is of a much lower dimension than the raw data. As a result, **we can train ‚Äì and predict ‚Äì on the full training set very quickly**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26249513",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_pca_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094f6f9",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- And the test set accuracy is still good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248914a1",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_pca_log.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b9767",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parting thoughts üëã\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e3c11",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/transcript.png\" width=800><br>Suraj's freshman year transcript.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d827de5d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Thank you, and keep in touch!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca1a94c",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Thank you** for signing up for this brand-new class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acdc3d",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The course would not have been possible without our GSIs, IAs, and readers: Nishant Kheterpal, Yutong Li, Pranavi Pratapa, Neeru Uppalapati, Tahseen Younus, and Jingrui Zhang."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36371da",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Don't be a stranger ‚Äì our contact information is at [practicaldsc.org/staff](https://practicaldsc.org/staff). We want to hear about what you do after this class.<br><small>This quarter's course website will remain online permanently, so you can refer back to the content.</small>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "None",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
